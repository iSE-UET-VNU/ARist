{"cells":[{"cell_type":"markdown","source":["# LSTM model training\n","Change the paths, `project` and `train_len` and run the notebook.\n"],"metadata":{"id":"3_IrlCF_2Xcm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gmD0ELr9_9Gt"},"outputs":[],"source":["# %tensorflow_version 2.x\n","# import tensorflow as tf[\n","# device_name = tf.test.gpu_device_name()\n","# if device_name != '/device:GPU:0':\n","#     raise SystemError('GPU device not found')]\n","# print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1VZNQNaUAIZA"},"outputs":[],"source":["import csv\n","import os\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout, Embedding\n","from tensorflow.keras import optimizers\n","from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","from pickle import dump, load\n","import tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FZn4EcbkAKcR"},"outputs":[],"source":["class DataGenerator(tensorflow.keras.utils.Sequence):\n","    def __init__(self, data_path, data_size, batch_size, vocabulary_size,\n","                 to_fit=True, shuffle=True):\n","        self.data_path = data_path\n","        self.data_size = data_size\n","        self.batch_size = batch_size\n","        self.vocabulary_size = vocabulary_size\n","        self.to_fit = to_fit\n","        self.shuffle = shuffle\n","        # self.on_epoch_end()\n","\n","    def __len__(self):\n","        return int(np.ceil(self.data_size / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        df = pd.read_csv(\n","            self.data_path, skiprows=range(1, index * self.batch_size),\n","            nrows=self.batch_size)\n","        if self.shuffle:\n","            df = sklearn.utils.shuffle(df)\n","        x = df.iloc[:, :-1]\n","        y = df.iloc[:, -1]\n","        return np.array(x), to_categorical(y, num_classes=self.vocabulary_size + 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZYe974MAMI2"},"outputs":[],"source":["def read_file(filepath):\n","    with open(filepath) as f:\n","        str_text = f.read()\n","    return str_text\n","\n","project = 'eclipse'\n","fold = 9\n","train_len = 6\n","train_len_str = '6'\n","text_sequences = []\n","tokenizer = load(open(f'/content/drive/MyDrive/shared/LSTM-Kien/tokenizer/{project}/{project}.tk', 'rb'))\n","\n","vocabulary_size = len(tokenizer.word_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PhWeCi8KANbB"},"outputs":[],"source":["def count_lines_csv(file_path):\n","    input_file = open(file_path, 'r')\n","    reader_file = csv.reader(input_file)\n","    return len(list(reader_file))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"acyAZLmlAO5V"},"outputs":[],"source":["train_csv_path = f'/content/drive/MyDrive/shared/LSTM-Kien/train_data/{project}/{project}.csv'\n","batch_size = 2048\n","train_data_size = count_lines_csv(train_csv_path)\n","training_batch_generator = DataGenerator(train_csv_path, train_data_size, batch_size, vocabulary_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FU1dkNlnAP8_"},"outputs":[],"source":["def create_model(vocabulary_size, seq_len):\n","    model = Sequential()\n","    model.add(Embedding(vocabulary_size, 20, input_length=seq_len))\n","    # model.add(LSTM(64, return_sequences=True))\n","    model.add(LSTM(64))\n","    # model.add(LSTM(64,recurrent_dropout=0.1))\n","    model.add(Dropout(0.15))\n","    # model.add(Dense(64,activation='relu'))\n","    # model.add(Dropout(0.2))\n","    model.add(Dense(vocabulary_size, activation='softmax'))\n","    opt_adam = optimizers.Adam()\n","    model.compile(loss='categorical_crossentropy', optimizer=opt_adam, metrics=['accuracy'])\n","    model.summary()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjUjUAI7ARKI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d77b39a7-2740-4005-ede2-2187705f504e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","5011/5011 [==============================] - ETA: 0s - loss: 2.4731 - accuracy: 0.5930\n","Epoch 1: loss improved from inf to 2.47309, saving model to /content/drive/MyDrive/shared/LSTM-Kien/model/eclipse/eclipse.h5\n","5011/5011 [==============================] - 31239s 6s/step - loss: 2.4731 - accuracy: 0.5930\n","Epoch 2/60\n","5011/5011 [==============================] - ETA: 0s - loss: 2.4430 - accuracy: 0.5953\n","Epoch 2: loss improved from 2.47309 to 2.44305, saving model to /content/drive/MyDrive/shared/LSTM-Kien/model/eclipse/eclipse.h5\n","5011/5011 [==============================] - 37283s 7s/step - loss: 2.4430 - accuracy: 0.5953\n","Epoch 3/60\n","1017/5011 [=====>........................] - ETA: 9:37:57 - loss: 2.3878 - accuracy: 0.5991"]}],"source":["model_path = f\"/content/drive/MyDrive/shared/LSTM-Kien/model/{project}/{project}.h5\"\n","# if os.path.isfile(model_path):\n","model = load_model(model_path)\n","# else:\n","    # model = create_model(vocabulary_size + 1, train_len - 1)\n","checkpoint = ModelCheckpoint(model_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","epoch = 60\n","if __name__ == '__main__':\n","    model.fit(x=training_batch_generator,\n","                epochs=epoch,\n","                verbose=1,\n","                use_multiprocessing=True,\n","                callbacks=[checkpoint],\n","                shuffle=True)"]}],"metadata":{"accelerator":"GPU","colab":{"name":"LSTM_model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UwZnXmOrfQma3rwCISHU0TEu1DyeEiw7","authorship_tag":"ABX9TyPAjRWPgEuxTU5XCObvM8ro"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}