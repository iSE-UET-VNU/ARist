{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKYC1d_h-1T7"
      },
      "source": [
        "## CUDA setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvgme1E3IJfB",
        "outputId": "a7284f98-ba8f-4957-f0b5-9cde8e44dc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  libnvinfer-dev libnvinfer-plugin7 libnvinfer7\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 143 MB of archives.\n",
            "After this operation, 520 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer7 7.0.0-1+cuda10.0 [69.6 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer-dev 7.0.0-1+cuda10.0 [71.6 MB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer-plugin7 7.0.0-1+cuda10.0 [2,109 kB]\n",
            "Fetched 143 MB in 3s (45.0 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libnvinfer7.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../libnvinfer7_7.0.0-1+cuda10.0_amd64.deb ...\n",
            "Unpacking libnvinfer7 (7.0.0-1+cuda10.0) ...\n",
            "Selecting previously unselected package libnvinfer-dev.\n",
            "Preparing to unpack .../libnvinfer-dev_7.0.0-1+cuda10.0_amd64.deb ...\n",
            "Unpacking libnvinfer-dev (7.0.0-1+cuda10.0) ...\n",
            "Selecting previously unselected package libnvinfer-plugin7.\n",
            "Preparing to unpack .../libnvinfer-plugin7_7.0.0-1+cuda10.0_amd64.deb ...\n",
            "Unpacking libnvinfer-plugin7 (7.0.0-1+cuda10.0) ...\n",
            "Setting up libnvinfer7 (7.0.0-1+cuda10.0) ...\n",
            "Setting up libnvinfer-dev (7.0.0-1+cuda10.0) ...\n",
            "Setting up libnvinfer-plugin7 (7.0.0-1+cuda10.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y --no-install-recommends libnvinfer7=7.0.0-1+cuda10.0 \\\n",
        "    libnvinfer-dev=7.0.0-1+cuda10.0 \\\n",
        "    libnvinfer-plugin7=7.0.0-1+cuda10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Installing necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBkpRgBCBS2_",
        "outputId": "25e8c545-8143-471c-e07b-3b82708adba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting tensorflow-gpu==1.15.2\n",
            "  Downloading tensorflow_gpu-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (410.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 410.9 MB 33 kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.43.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.21.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.13.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.2) (1.15.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=05965e73e1da1dcd9d77794c8fc1742f2e116ea1ccae426fbbe02e7449cbebec\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: gast, tensorflow-gpu\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 tensorflow-gpu-1.15.2\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "#!pip install tensorflow==1.15.2\n",
        "!pip install tensorflow-gpu==1.15.2\n",
        "!pip install -q gpt-2-simple==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQFo2PINvblo",
        "outputId": "5bffaf14-8aa6-44c9-a42a-feb9c8d0b967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## Verifying GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUmTooTW3osf",
        "outputId": "d3c34e4b-16e3-4d35-cb62-c6c5cde1c464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Dec 27 08:15:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tgvl-BJ7I4H",
        "outputId": "a862ccb9-7269-4cae-e095-f16638cf410b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 5661350125407305619\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 15334983247480132462\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 8196194454160575818\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 15964005991\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 5373410271582225779\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxKEhGLhQ2H0",
        "outputId": "e5a83dac-2c7a-4a96-eaa1-8786c0ef29e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "outputs": [],
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='9000')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Ranking candidates using GPT-2\n",
        "before combining additional features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_TNaVORx5Mb"
      },
      "outputs": [],
      "source": [
        "!cp -R drive/MyDrive/shared/GPT/gpt gpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlD93fzPsmo_"
      },
      "outputs": [],
      "source": [
        "from gpt.gpt_manager import GPTManager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVeJYgBAXT3h"
      },
      "outputs": [],
      "source": [
        "gpt_manager = GPTManager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cb7co1DZthy",
        "outputId": "2f6c5f96-f08c-400e-b710-909a7cabacdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "244 end tokens.\n",
            "Loading model checkpoint/run1/model-150000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-150000\n",
            "WARNING:tensorflow:From /content/gpt/sample.py:33: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "gpt_manager.java_model = gpt_manager.load_model('checkpoint/', 'run1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9iwWx-Lc4oR"
      },
      "outputs": [],
      "source": [
        "main_path = \"drive/MyDrive/shared/GPT/\"\n",
        "repo_dir = \"four_hundred/\"\n",
        "tests_path = main_path + \"tests/\" + repo_dir\n",
        "setting = \"dynamic\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EgXSI_Gdimb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def readTests(projectName):\n",
        "    if setting == \"maintenance\":\n",
        "        filePathSet = set()\n",
        "        with open(f\"{main_path}test_file_paths/maintenance_files.txt\") as f:\n",
        "            lines = f.read().split('\\n')\n",
        "            for line in lines:\n",
        "                if len(line) > 0:\n",
        "                  filePathSet.add(line[line.index(\"java_repos/\")+len(\"java_repos/\"):])\n",
        "\n",
        "    oneArgTests = []\n",
        "    with open(f\"{tests_path}{projectName}_ArgRecTests.txt\") as f:\n",
        "        lines = f.read().split('\\n')\n",
        "        for line in lines[:-1]:\n",
        "            oneArgTest = json.loads(line)\n",
        "            if setting != \"maintenance\" or (projectName + '/' + oneArgTest['filePath']) in filePathSet:\n",
        "                oneArgTests.append(oneArgTest)\n",
        "        lines = None\n",
        "    return oneArgTests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGJJ4ZQn6IaN"
      },
      "outputs": [],
      "source": [
        "def allTestsToNonZeroArgRecTest(oneArgTests):\n",
        "    tests = []\n",
        "    for i in range(len(oneArgTests)):\n",
        "        test = oneArgTests[i]\n",
        "        # SKIP METHOD INVOCATIONS WITH NO ARGUMENT PASSED\n",
        "        if test['argPos'] > 0:\n",
        "            tests.append(test)\n",
        "    return tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo5f8WZvx2zz"
      },
      "outputs": [],
      "source": [
        "def readFilterPreds(projectName):\n",
        "    filters_predictions = []\n",
        "    with open(f\"{main_path}predictions/{repo_dir}filter_{setting}/{projectName}/{projectName}_prediction_detail_flute_sequence.txt\") as f:\n",
        "        lines = f.read().split('\\n')\n",
        "        for line in lines:\n",
        "            if len(line) > 0:\n",
        "                filters_predictions.append(json.loads(line))\n",
        "        lines = None\n",
        "    return filters_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fkfj-jgH_eP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def readMapping(projectName):\n",
        "    with open(f\"{main_path + 'test_mappings/'}{projectName}_ArgRecTests_mapping.npy\", 'rb') as f:\n",
        "        return np.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-E_dDMJKWMA"
      },
      "outputs": [],
      "source": [
        "def correctPredsOrder(preds, test_mapping):\n",
        "    correctPreds = []\n",
        "    for i in range(len(test_mapping)):\n",
        "        correctPreds.append(preds[test_mapping[i]])\n",
        "    return correctPreds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VErRoqgPz1O9"
      },
      "outputs": [],
      "source": [
        "def use_gpt_to_predict(candidate):\n",
        "    # COMPOUND\n",
        "    if candidate == \"<COMPOUND>\":\n",
        "        return True\n",
        "\n",
        "    # LAMBDA\n",
        "    if candidate == \"<LAMBDA>\":\n",
        "        return True\n",
        "\n",
        "    # NULL_LIT\n",
        "    if candidate == \"null\":\n",
        "        return False\n",
        "\n",
        "    # BOOL_LIT\n",
        "    if candidate == \"true\" or candidate == \"false\":\n",
        "        return False\n",
        "\n",
        "    # NUM_LIT, CHAR_LIT\n",
        "    if candidate == \"0\":\n",
        "        return False\n",
        "\n",
        "    # THIS, SUPER\n",
        "    if candidate == \"this\" or candidate == \"super\":\n",
        "        #return main_score\n",
        "        return False\n",
        "\n",
        "    # CAST\n",
        "    if candidate[0] == \"(\":\n",
        "        return False\n",
        "\n",
        "    # M_REF\n",
        "    if \"::\" in candidate:\n",
        "        return True\n",
        "\n",
        "    # NAME, TYPE_LIT, LAMBDA\n",
        "    if (candidate[-1] not in [\"(\", \"\\\"\", \"[\", \"]\"]) and (candidate != \"null\"):\n",
        "        if candidate.find('.') <= 0 or \"->\" in candidate:\n",
        "            return True\n",
        "\n",
        "    # FIELD_ACCESS\n",
        "    if (candidate[-1] not in [\"(\", \"\\\"\", \"[\", \"]\"]) and (candidate != \"null\"):\n",
        "        if candidate.find('.') > 0 and \"->\" not in candidate:\n",
        "            return False\n",
        "\n",
        "    # METHOD_INVOC\n",
        "    if candidate[-1] == \"(\" and not candidate.startswith(\"new \"):\n",
        "        return False\n",
        "\n",
        "    # OBJECT_CREATION\n",
        "    if candidate[-1] == \"(\" and candidate.startswith(\"new \"):\n",
        "        #return main_score\n",
        "        return False\n",
        "\n",
        "    # ARRAY_ACCESS, ARR_CREATION\n",
        "    if candidate[-1] in [\"[\", \"]\"]:\n",
        "        return True\n",
        "\n",
        "    # STRING_LIT\n",
        "    if candidate[-1] == \"\\\"\":\n",
        "        return False\n",
        "\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAAU33_c1K_8"
      },
      "outputs": [],
      "source": [
        "PREDICTION_COUNT_LIM = 20\n",
        "\n",
        "def allTestsToFilteredTest(oneArgTests, filters_predictions):\n",
        "    for i in range(len(oneArgTests)):\n",
        "        #prediction_set = set(filters_predictions[i]['predictions'][:PREDICTION_COUNT_LIM])\n",
        "        prediction_set = set()\n",
        "        for candidate in filters_predictions[i]['predictions'][:PREDICTION_COUNT_LIM]:\n",
        "            if use_gpt_to_predict(candidate):\n",
        "                prediction_set.add(candidate)\n",
        "                if len(prediction_set) == PREDICTION_COUNT_LIM:\n",
        "                    break\n",
        "        for j in range(len(oneArgTests[i]['next_lex'])):\n",
        "            lex_candidate_list = []\n",
        "            for candidate in oneArgTests[i]['next_lex'][j]:\n",
        "                if candidate in prediction_set:\n",
        "                    lex_candidate_list.append(candidate)\n",
        "                    prediction_set.remove(candidate)\n",
        "            oneArgTests[i]['next_lex'][j] = lex_candidate_list\n",
        "\n",
        "        # TODO: Add proper excode candidates\n",
        "        if len(prediction_set) > 0:\n",
        "            oneArgTests[i]['next_excode'].append(None)\n",
        "            oneArgTests[i]['next_lex'].append(list(prediction_set))\n",
        "        excode_candidate_list = []\n",
        "        lex_candidate_list = []\n",
        "        for j in range(len(oneArgTests[i]['next_lex'])):\n",
        "            if len(oneArgTests[i]['next_lex'][j]) > 0:\n",
        "                excode_candidate_list.append(oneArgTests[i]['next_excode'][j])\n",
        "                lex_candidate_list.append(oneArgTests[i]['next_lex'][j])\n",
        "        oneArgTests[i]['next_excode'] = excode_candidate_list\n",
        "        oneArgTests[i]['next_lex'] = lex_candidate_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23kjL0oW1Cqa"
      },
      "outputs": [],
      "source": [
        "def toSingleArgRecTest(this):\n",
        "    test = {}\n",
        "    test['filePath'] = this['filePath']\n",
        "    test['numArg'] = 1 if this['argPos'] != 0 else 0\n",
        "    test['lex_context'] = this['lex_context']\n",
        "    test['excode_context'] = this['excode_context']\n",
        "    test['next_excode'] = [this['next_excode']]\n",
        "    test['next_lex'] = [this['next_lex']]\n",
        "    test['expected_excode'] = this['expected_excode']\n",
        "    test['expected_lex'] = this['expected_lex']\n",
        "    test['ignored'] = this['ignored']\n",
        "    test['argRecTestList'] = [this]\n",
        "    test['id'] = this['test_id']\n",
        "    return test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d67IQ8C91IMc"
      },
      "outputs": [],
      "source": [
        "def allTestsToSingleArgRecTest(oneArgTests):\n",
        "    tests = []\n",
        "    for i in range(len(oneArgTests)):\n",
        "        test = oneArgTests[i]\n",
        "        # SKIP METHOD INVOCATIONS WITH NO ARGUMENT PASSED\n",
        "        #if test['argPos'] > 0:\n",
        "        if True:\n",
        "            test = toSingleArgRecTest(test)\n",
        "            tests.append(test)\n",
        "    return tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MGnjcGWy6dH"
      },
      "outputs": [],
      "source": [
        "from gpt import preprocessor\n",
        "\n",
        "def preprocess(target):\n",
        "    target = preprocessor.empty_string_literal(target)\n",
        "    target = preprocessor.remove_array_access_index(target)\n",
        "    return target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDWp3yqL7Ka1"
      },
      "outputs": [],
      "source": [
        "def preprocess_filter(candidate):\n",
        "    candidate = preprocessor.empty_string_literal(candidate)\n",
        "    if \"{\" in candidate:\n",
        "        candidate = candidate[:candidate.index(\"{\")].rstrip()\n",
        "    if \"]\" in candidate:\n",
        "        candidate = preprocessor.remove_array_access_index(candidate)\n",
        "    if \"(\" in candidate and candidate.index(\"(\") > 0:\n",
        "        candidate = preprocessor.normalize_method_invocation(candidate)\n",
        "\n",
        "    # Lambda expression\n",
        "    if \"->\" in candidate:\n",
        "        candidate = \"x -> {}\"\n",
        "\n",
        "    # Exclude candidates starting with this if they are redundant\n",
        "    if candidate.startswith(\"this.\"):\n",
        "        candidate = candidate[5:]\n",
        "\n",
        "    return candidate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlN8Rgy77Osj"
      },
      "outputs": [],
      "source": [
        "def preprocess_all_filter_preds(filters_predictions):  \n",
        "  for i in range(len(filters_predictions)):\n",
        "      for j in range(len(filters_predictions[i]['predictions'])):\n",
        "          filters_predictions[i]['predictions'][j] = preprocess_filter(filters_predictions[i]['predictions'][j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6HyRqvGa6fY"
      },
      "outputs": [],
      "source": [
        "def matchesArg(expectedLex, result):\n",
        "    if result == expectedLex:\n",
        "        return True\n",
        "\n",
        "    if '->' in expectedLex and '->' in result:\n",
        "        return True\n",
        "\n",
        "    if '.this' in expectedLex:\n",
        "        if matchesArg(expectedLex[expectedLex.index('.this')+1:], result):\n",
        "            return True\n",
        "\n",
        "    if '.this' in result:\n",
        "        if matchesArg(expectedLex, result[result.index('.this')+1:]):\n",
        "            return True\n",
        "\n",
        "    if expectedLex.startswith('this.'):\n",
        "        if matchesArg(expectedLex[5:], result):\n",
        "            return True\n",
        "\n",
        "    if result.startswith('this.'):\n",
        "        if matchesArg(expectedLex, result[5:]):\n",
        "            return True\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaWz9QQsAXoV"
      },
      "outputs": [],
      "source": [
        "def canAcceptGeneratedLexes(test):\n",
        "    test = test['argRecTestList'][0]\n",
        "\n",
        "    expectedLex = test['expected_lex']\n",
        "\n",
        "    expectedLex = preprocess(expectedLex)\n",
        "    if '{' in expectedLex:\n",
        "        expectedLex = expectedLex[:expectedLex.index('{')].rstrip()\n",
        "\n",
        "    for group in test['next_lex']:\n",
        "        for candidate in group:\n",
        "            candidate = preprocess(candidate)\n",
        "            if matchesArg(expectedLex, candidate):\n",
        "                return True\n",
        "\n",
        "            alternateLex = None\n",
        "            if 'methodAccessLex' in test:\n",
        "                alternateLex = test['methodAccessLex']\n",
        "            if 'objectCreationLex' in test:\n",
        "                alternateLex = test['objectCreationLex']\n",
        "            if alternateLex is not None and matchesArg(alternateLex, candidate):\n",
        "                return True\n",
        "\n",
        "            if 'staticMemberAccessLex' in test:\n",
        "                if matchesArg(test['staticMemberAccessLex'], candidate):\n",
        "                    return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUdqQfcBbA0A"
      },
      "outputs": [],
      "source": [
        "expressionTypes = ['NAME', 'METHOD_INVOC', 'FIELD_ACCESS', 'ARRAY_ACCESS', 'CAST', 'STRING_LIT', 'NUM_LIT', 'CHAR_LIT', 'TYPE_LIT', 'BOOL_LIT',\n",
        "    'NULL_LIT', 'OBJ_CREATION', 'ARR_CREATION', 'THIS', 'SUPER', 'COMPOUND', 'LAMBDA', 'METHOD_REF']\n",
        "expressionTypeDict = {}\n",
        "\n",
        "for i in range(len(expressionTypes)):\n",
        "    expressionTypeDict[expressionTypes[i]] = i\n",
        "\n",
        "tops = [1, 3, 5, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqn5PBv8c19j"
      },
      "outputs": [],
      "source": [
        "def validateTest(test):\n",
        "    if not test['ignored']:\n",
        "        adequateGeneratedLex = False\n",
        "        if canAcceptGeneratedLexes(test):\n",
        "            adequateGeneratedLex = True;\n",
        "        if adequateGeneratedLex:\n",
        "            return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCzjVqmp-3Eg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "\n",
        "PREDICT_PERCENT = 100\n",
        "\n",
        "if PREDICT_PERCENT == 100:\n",
        "    os.makedirs(f'predictions/{repo_dir}flute_{setting}/', exist_ok=True)\n",
        "else:\n",
        "    os.makedirs(f'predictions_{PREDICT_PERCENT}/{repo_dir}flute_{setting}/', exist_ok=True)\n",
        "\n",
        "for testFile in os.listdir(tests_path):\n",
        "    projectName = testFile[:testFile.find(\"_ArgRecTests\")]\n",
        "    if PREDICT_PERCENT == 100:\n",
        "        predictionFilePath = f'predictions/{repo_dir}flute_{setting}/{projectName}_ArgRecs.txt'\n",
        "    else:\n",
        "        predictionFilePath = f'predictions_{PREDICT_PERCENT}/{repo_dir}flute_{setting}/{projectName}_ArgRecs.txt'\n",
        "    if os.path.isfile(main_path + predictionFilePath):\n",
        "        continue\n",
        "    if os.path.isfile(main_path + f'predictions/{repo_dir}flute_{setting}/{projectName}_ArgRecs.txt'):\n",
        "        continue\n",
        "    print(projectName)\n",
        "    prediction_details = []\n",
        "    tests = readTests(projectName)\n",
        "    filter_preds = readFilterPreds(projectName)\n",
        "    if setting != \"maintenance\":\n",
        "        filter_preds = correctPredsOrder(filter_preds, readMapping(projectName))\n",
        "\n",
        "    allTestsToFilteredTest(tests, filter_preds)\n",
        "    tests = allTestsToSingleArgRecTest(tests)\n",
        "    preprocess_all_filter_preds(filter_preds)\n",
        "\n",
        "    assert len(tests) == len(filter_preds), \"Tests not matched!\"\n",
        "    for i in range(len(tests)):\n",
        "        assert tests[i]['expected_lex'][:3] == filter_preds[i]['answer'][:3], \"Tests not matched!\"\n",
        "\n",
        "    tests = tests[: len(tests) * PREDICT_PERCENT // 100]\n",
        "    for i in tqdm(range(len(tests))):\n",
        "        test = tests[i]\n",
        "        if test['numArg'] == 0:\n",
        "            continue\n",
        "        \n",
        "        response = gpt_manager.predict_param_using_lex(test)\n",
        "        gptResults = response['result']\n",
        "        gptScores = response['scores']\n",
        "\n",
        "        prediction_dict = {}\n",
        "        for j in range(len(filter_preds[i]['predictions']) - 1, -1, -1):\n",
        "            prediction_dict[filter_preds[i]['predictions'][j]] = filter_preds[i]['lexModelScores'][j]\n",
        "            # # CAST\n",
        "            # if filter_preds[i]['predictions'][j][0] == '(':\n",
        "            #     prediction_dict[filter_preds[i]['predictions'][j]] += np.log(0.1)\n",
        "            if prediction_dict[filter_preds[i]['predictions'][j]] > 0:\n",
        "                prediction_dict[filter_preds[i]['predictions'][j]] = -64\n",
        "\n",
        "        for j in range(len(gptResults)):\n",
        "            prediction_dict[gptResults[j]] = gptScores[j]\n",
        "        combinedResults = sorted(list(set(filter_preds[i]['predictions'])), key=lambda x: -prediction_dict[x])\n",
        "\n",
        "        prediction_detail = {}\n",
        "        prediction_detail['test_id'] = test['id']\n",
        "        prediction_detail['predictions'] = combinedResults\n",
        "        prediction_detail['scores'] = [prediction_dict[x] for x in combinedResults]\n",
        "        prediction_detail['answer'] = test['expected_lex']\n",
        "        prediction_detail['arg_type'] = test['argRecTestList'][0]['argType']\n",
        "        prediction_detail['runtime'] = response['runtime']\n",
        "        prediction_detail['ignored'] = test['ignored']\n",
        "        prediction_detail['sufficient_candidates'] = validateTest(test)\n",
        "        prediction_details.append(prediction_detail)\n",
        "\n",
        "    with open(predictionFilePath, \"w\") as f:\n",
        "        for prediction_detail in prediction_details:\n",
        "            f.write(json.dumps(prediction_detail) + '\\n')\n",
        "\n",
        "    shutil.copyfile(predictionFilePath, main_path + predictionFilePath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YQkrx5q-6Br"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "PEARL_predict_large_corpus.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}